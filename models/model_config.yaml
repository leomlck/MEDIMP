# Adapted from https://github.com/revantteotia/clip-training/blob/5ed4f22a1522c8dbc9c22482d77c0e95a0c0a0f0/model/model_config.yaml

RN50: 
  embed_dim : 1024
  image_resolution : [96, 144, 192] #224
  vision_layers : [3, 4, 6, 3]
  vision_width : 64
  vision_patch_size : 0 # ideally it should be none
  context_length : 77
  vocab_size : 49408
  transformer_width : 512
  transformer_heads : 8
  transformer_layers : 12 #6 # 12 in CLIP

ViTB16:
  vision_width : 768
  vision_layers : 12
  vision_patch_size : 16
  image_resolution : [96, 144, 192]
  embed_dim : 512
  context_length : 77
  vocab_size : 49408
  transformer_width : 512
  transformer_heads : 8
  transformer_layers : 12
